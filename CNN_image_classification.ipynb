{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d324362c",
   "metadata": {},
   "source": [
    "## import all the packages/libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8674f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6868cfb",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4925b198",
   "metadata": {},
   "source": [
    "Normalize the inputs from 0-255 to between 0 and 1dividing by 255\n",
    "1. The input values are the pixels in the image, which have a value between 0\n",
    "to 255.\n",
    "2. So in order to normalize the data we can simply divide the image values by\n",
    "255. To do this we first need to make the data a float type, since they are\n",
    "currently integers. We can do this by using the astype() Numpy command\n",
    "and then declaring what data type we want\n",
    " The augmentation of Image: This is basically synthesising the training data. to do this\n",
    "using keras.preprocessing library for doing the synthesising part as well as to prepare\n",
    "the training set as well as the test test set of images that are present in a properly\n",
    "structured directories, where the directory’s name is take as the label of all the\n",
    "images present in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7bfe265d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 images belonging to 2 classes.\n",
      "Found 43 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=ImageDataGenerator(rescale=1/255)\n",
    "validation=ImageDataGenerator(rescale=1/255)\n",
    "train_dataset=train.flow_from_directory(\"C:/Users/user/Building-Image-Classification/data/training\",\n",
    "target_size=(200,200),\n",
    "batch_size=3,\n",
    "class_mode='binary')\n",
    "validation_dataset=validation.flow_from_directory(\"C:/Users/user/Building-Image-Classification/data/validation\",\n",
    "target_size=(200,200),\n",
    "batch_size=3,\n",
    "class_mode='binary')\n",
    "train_dataset.class_indices\n",
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bbb0fd",
   "metadata": {},
   "source": [
    "## build the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e71aa9",
   "metadata": {},
   "source": [
    "Step 1: Convolution\n",
    "Step 2: Pooling\n",
    "Step 3: Flattening\n",
    "Step 4: Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "09b89eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(200,200,3)),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Conv2D(64,(3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Flatten(),\n",
    "tf.keras.layers.Dense(512,activation='relu'),\n",
    "tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50fc45",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d642345",
   "metadata": {},
   "source": [
    "Steps 4: Compile the Model\n",
    "1. After the model is created, you compile it using the Adam optimizer, one of the\n",
    "most popular optimization algorithms\n",
    "2. Additionally, specify the loss type which is categorical cross entropy which is used\n",
    "for multi-class classification, use binary cross-entropy as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7b5ebce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer=RMSprop(lr=0.001),\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc1cb1",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df9012",
   "metadata": {},
   "source": [
    "1. Train the model with Keras' fit() function.\n",
    "2. Define the model epochs.\n",
    "3. Print out the model summary to see what the whole model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "74c983a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Building-Image-Classification\\CNN_image_classification.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Building-Image-Classification/CNN_image_classification.ipynb#ch0000013?line=0'>1</a>\u001b[0m model_fit\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(train_dataset,epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49mvalidation_dataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Building-Image-Classification/CNN_image_classification.ipynb#ch0000013?line=1'>2</a>\u001b[0m validation_dataset\u001b[39m.\u001b[39mclass_indices\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\image_utils.py:386\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    384\u001b[0m   color_mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgrayscale\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m pil_image \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not import PIL.Image. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    387\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mThe use of `load_img` requires PIL.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, io\u001b[39m.\u001b[39mBytesIO):\n\u001b[0;32m    389\u001b[0m   img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39mopen(path)\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "model_fit=model.fit(train_dataset,epochs=10,validation_data=validation_dataset)\n",
    "validation_dataset.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ec580",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ea9a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`y` argument is not supported when using `keras.utils.Sequence` as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Building-Image-Classification\\CNN_image_classification.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Building-Image-Classification/CNN_image_classification.ipynb#ch0000020?line=0'>1</a>\u001b[0m \u001b[39m# Model evaluation \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Building-Image-Classification/CNN_image_classification.ipynb#ch0000020?line=1'>2</a>\u001b[0m scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(train_dataset,validation_dataset, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Building-Image-Classification/CNN_image_classification.ipynb#ch0000020?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m%%\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (scores[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\data_adapter.py:916\u001b[0m, in \u001b[0;36mKerasSequenceAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    906\u001b[0m              x,\n\u001b[0;32m    907\u001b[0m              y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m              model\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    914\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    915\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_none_or_empty(y):\n\u001b[1;32m--> 916\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`y` argument is not supported when using \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m`keras.utils.Sequence` as input.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    918\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_none_or_empty(sample_weights):\n\u001b[0;32m    919\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`sample_weight` argument is not supported when using \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    920\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m`keras.utils.Sequence` as input.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: `y` argument is not supported when using `keras.utils.Sequence` as input."
     ]
    }
   ],
   "source": [
    "# Model evaluation \n",
    "scores = model.evaluate(train_dataset,validation_dataset, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1412b37c",
   "metadata": {},
   "source": [
    "## Model Prediction\n",
    "1. Pre-process Image \n",
    "2. Making new predictions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image =\n",
    "image.load_img('C:/Users/user/Building-Image-Classification/data/testing/14.jpg',\n",
    "target_size = (200, 200))\n",
    "plt.imshow(test_image)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(\"The image is \"+prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a926afa313b26ae1264fdcf81c726a97e69f6ba2ba780f6aa901948710f8d6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
